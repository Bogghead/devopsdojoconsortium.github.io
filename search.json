[

 {
  "title": "Average Build Downtime",
  "url": "/docs/playbooks/metrics/average-build-downtime.html",
  "content": "Average Build DowntimeThe average length of time between when a build breaks and when it is fixed.What is the intended behavior?Keep the pipelines always deployable by fixing broken builds as rapidly as possible. Broken builds are the highest priority sincethey prevent production fixes from being deployed in a safe, standard way.How is it improved?  Refactor to improve testability and modularity.  Improve tests to locate problems more rapidly.  Decrease the size of the component to reduce complexity.  Add automated alerts for broken builds.  Ensure the proper team practice is in place to support each other in solving the problem as a team.How is it gamed?  Re-build the previous version.  Remove tests that are failing.When over-emphasized, what metrics are impacted?  Commit frequency decreases as additional manual or automated process overhead is added before integration to master.  Productivity decreases as manual verification steps are added to ensure each pull request does not break the build."
 },
 {
  "title": "Behavior Driven Development",
  "url": "/docs/playbooks/lean/work-decomposition/behavior-driven-development.html",
  "content": "Behavior Driven DevelopmentBehavior Driven Development acceptance criteria are the testable outcomes agreed upon by the team,including development, quality, and business that express the definition of done for a user story.Recommended PracticesAll tests follow the Arrange, Act, Assert pattern. Gherkin is a domain specific language that allows acceptance criteria to be expressed with this pattern in a way that is understandable to all stakeholders.Example:As an hourly associate I want to be able to log my arrival time so that I can be paid correctly.Given I am not clocked inWhen I enter my associate numberThen my arrival time will be loggedAnd I will be notified of the timeGiven I am clocked inWhen I enter my associate numberAnd I have been clocked in for more than 5 minutesThen I will be clocked outAnd I will be notified of the timeGiven I am clocked inWhen I enter my associate numberAnd I have been clocked in for less than 5 minutesThen I will receive an errorUsing Acceptance Criteria to Negotiate and SplitWith the above criteria, it may be acceptable to remove the time validation and accelerate delivery of the time logging ability. After delivery, the validation may not be required. If true, weve saved money and time by NOT delivering unneeded features.First we deliver the ability to clock in and see if we really do need the ability to verify.As an hourly associate I want to be able to log my arrival time so that I can be paid correctly.Given I am not clocked inWhen I enter my associate numberThen my arrival time will be loggedAnd I will be notified of the timeGiven I am clocked inWhen I enter my associate numberThen I will be clocked outAnd I will be notified of the timeIf, in production, we discover that the sanity check is required to prevent time clock issues, we can quickly add that behavior.As an hourly associate I want to be prevented from clocking out immediately after clocking in.Given I am clocked inAnd I have been clocked in for more than 5 minutesWhen I enter my associate numberThen I will be clocked outAnd I will be notified of the timeGiven I am clocked inAnd I have been clocked in for less than 5 minutesWhen I enter my associate numberThen I will receive an errorTips  Scenarios should be written from the point of view of the consumer.  Scenarios should be focused on a specific function and should not attempt to describe multiple behaviors.  If a story has more than 6 acceptance criteria, it can probably be split.  No acceptance test should contain more than 10 conditions. In fact, much less is recommended.ValueAs a development team, we want to know the specific behaviors that define done for a user story so that we can predict delivery with a high level of confidence.Acceptance Criteria  All stakeholders agree that the scenarios fully describe the deliverable.  The scenarios are testable.  The scenarios are declarative. They describe what the expected behavior is, but not how it will be implemented.  The scenarios avoid describing explicit UI activity unless it is critical to the outcomes.References  Gherkin Reference  BDD Process Information"
 },
 {
  "title": "Blog",
  "url": "/blog.html",
  "content": "Latest Member PostsThese are the opinions of individuals and do not represent the views of the Dojo Consortium or the members&#39;  employers.        Great change happens through small steps. A lot of them.    &amp;lt;img src=../assets/img/posts/6D524680-10E0-4BB5-ACE5-558A6C96E06B.pngwidth=90%alt=Post from Instagram: https://www.instagram.com/p/By0MZGPlsS1/?igshid=lhif13zps1la&amp;gt;The DevOps community provides sage advice to focus on outcomes. Outcomes in this context serve as the North Star to guide our improvement journey.For some of us focusing on outcomes can be daunting, especially when that outcome is so far away. If we are not careful, we can get lost in the minutia; stuck in the starters block. How do we get out of the starters block? I always tell my teams to make each day a little bit better than the day before. Make a small, simple improvement every day.Remember every successful journey starts with a single stepand ends with tired legs.This post originally appeared on Instagram. You can see other posts @the.devops.hive there          5 Minute DevOps - GitFlow Best Practices    I was asked recently about the best practice for using GitFlow with continuous integration. For those who do not know, this is GitFlow:    "
 },
 {
  "title": "Build Cycle Time",
  "url": "/docs/playbooks/metrics/build-cycle-time.html",
  "content": "Build Cycle TimeThe time from code commit to production deploy. This is the minimum time changes can be applied to production.What is the intended behavior?Reduce pipeline duration to improve MTTR and toamplify the quality signal by giving the team more rapid feedback to any issues.How is it improved?  Identify areas of the build that can run concurrently.  Replace integration tests in the pipeline with virtual services and move integration testing to an asynchronous process.  Remove unneeded code.  Break down large services into smaller domains.How is it gamed?  Reduce the number of tests running or test types executed.When over-driven, what metrics are impacted?  Quality decreases if testing steps are skipped."
 },
 {
  "title": "Change Fail Rate",
  "url": "/docs/playbooks/metrics/change-fail-rate.html",
  "content": "Change Fail RateThe percentage of changes that result in negative customer impact, or rollback.changeFailRate = failedChangeCount / changeCountSoftware delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time.What is the intended behavior?Reduce the percentage of failed changes to less than 15%.How is it improved?  Release more, smaller changes to make quality steps more effective and reduce the impact of failure.  Identify root cause for each failure and improve the automated quality checks.How is it gamed?  Deploy fixes without recording the defect.  Create defect review meetings and re-classify defects as feature requests.  Re-deploy the latest working version to increase deploy count.When over-driven, what metrics are impacted?  Release frequency decreases as focus is placed on zero defect changes.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate"
 },
 {
  "title": "Code Coverage",
  "url": "/docs/playbooks/metrics/code-coverage.html",
  "content": "Code CoverageMeasure of how many lines, branches, and functions are executed when automated tests are run. Industry average is ~80%, but this isconsidered a situational reference and not a goal.What is the intended behavior?Provide the information needed to identify risky or complicated portions of the code that are not sufficiently covered by tests.How is it improved?  Write tests for code that SHOULD be covered that isnt.  Refactor the application to improve testability.How is it gamed?  Tests are written for code that receives no value from testing.  Test code is written that does not check for failures.  Code is inappropriately excluded from test coverage reporting.Example: The following test will result in 100% function, branch, and line coverage with no behavior tested./* Returns the sum of two integers *//* Returns NaN for non-integers */function addWholeNumbers(a, b) {  if (a % 1 === 0 &amp;amp;&amp;amp; b % 1 === 0) {    return a + b;  } else {    return NaN;  }}it(&#39;Should add two whole numbers&#39; () =&amp;gt; {  expect(addWholeNumbers(2, 2)).to.not.be.NaN;  expect(addWholeNumbers(1.1, 0)).to.not.be.null;})The following will report the same code coverage resultsit(&#39;Should add two whole numbers&#39; () =&amp;gt; {  addWholeNumbers(2, 2)  addWholeNumbers(1.1, 0)})When over-driven, what metrics are impacted?  Development Cycle Time increases with additional development time dedicated to chasing the coverage metric.  Quality decreases as poor quality tests hide lack of real codecoverage."
 },
 {
  "title": "Coming soon",
  "url": "/docs/playbooks/coming-soon.html",
  "content": "Coming soonOh yeah, were working on it!"
 },
 {
  "title": "Commit Frequency",
  "url": "/docs/playbooks/metrics/commit-frequency.html",
  "content": "Commit FrequencyThe average number of times each developer on a teamintegrates tested, non-breaking code to trunk / master. Healthy CI practice is at least once per day per developer.What is the intended behavior?  Increase the frequency of code integration.  Reduce the size of each change.  Improve code review processes.How is it improved?  Break down code changes into smaller units to incrementally deliver features.  Use BDD to aid functional breakdown.  Use TDD to design more modular code that can be integrated more frequently.  Make new code reachable only by the tests or flagged off for otherenvironments with feature flags.How is it gamed?  Meaningless changes integrated to trunk.When over-driven, what metrics are impacted?  Quality decreases when testing is skipped.  Development Cycle Time increases due to additionalreview overhead.Recommended Practices  Trunk Based Development  Continuous Integration  Feature Flagging"
 },
 {
  "title": "Development Cycle Time",
  "url": "/docs/playbooks/metrics/development-cycle-time.html",
  "content": "Development Cycle TimeThe average time from starting work until release to production.Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time.What is the intended behavior?Reduce the time it takes to deliver refined work to production to mitigate the effects of priorities changing and to improve value delivery.How is it improved?  Decompose work so it can be delivered in smaller increments and by more team members.  Identify and remove process waste, handoffs, and delays in the construction process.  Improve testing efficiency for more rapid feedback loops.  Automate and standardize the build and deploy pipeline.How is it gamed?  Move things to Done status that are not in production.  Move items directly from Backlog to Done after deploying to production.  Split work into functional tasks that should be considered part of development (development task, testing task,etc.).When over-driven, what metrics are impacted?  Quality decreases as quality processes are skipped.  Change fail rate increases.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate"
 },
 {
  "title": "References",
  "url": "/docs/references/index.html",
  "content": "ReferencesContinuous Delivery isnt new. Its been commonplace in many companies for over a decade. Included here is a list of informationresources weve found helpful as weve continued to improve.  References          Microservices      Understanding DevOps      Continuous Integration      Continuous Delivery      Domain Driven Design      TDD/BDD      Pair Programming      Suggested Reading                  Accelerate: by Nicole Forsgren, Jez Humble, &amp;amp; Gene Kim          BDD in Action: by John Ferguson Smart          Continuous Delivery: by Jez Humble &amp;amp; David Farley          Implementing Domain-Driven Design: by Vaughn Vernon          Paul Hammant Blog          Working Effectively with Legacy Code by Michael Feathers                    References by Topic                  Architecture          Estimating Stories          Evolutionary Database          Evolutionary Development          Flow Management          Operational Stability          Product Ownership          Source Management          Strangler Pattern          Teamwork          Testing &amp;amp; Quality                    Feature Flags      Microservices  Microservices Architectural Design Patterns PlaybookUnderstanding DevOps  Understanding DevopsContinuous Integration  Continuous Integration  Integration TestingContinuous Delivery  Continuous Integration Big Picture  Implementing Continuous Delivery  Docker Ansible Continuous Delivery  Continuous-Database-DeliveryDomain Driven Design  Domain Driven Design Fundamentals  Domain Driven Design In Practice  Domain Driven Design Legacy Projects  Modern Software ArchitectureTDD/BDD  Test First Development Part-1  Test First Development Part-2  Outside In TDD  Test Driven Development Big Picture  Pragmatic-BDD-Dotnet  Clean Architecture Patterns  Pragmatic-Unit-Testing  TDD Junit5  TDD As Design Tool  Play By Play Wilson TDDPair Programming  Pair ProgrammingSuggested ReadingAccelerate: by Nicole Forsgren, Jez Humble, &amp;amp; Gene Kim  Purchase  Does technology actually matter? And how can we apply technology to drive business value?  For years, we&#39;ve been told that the performance of software delivery teams doesn&#39;t matter;  that it can&#39;t provide a competitive advantage to our companies.  Through four years of groundbreaking research, Dr. Nicole Forsgren, Jez Humble, and  Gene Kim set out to find a way to measure software delivery performanceand what drives  it, using rigorous statistical methods. This book presents both the findings and the  science behind that research. Readers will discover how to measure the performance of  their teams, and what capabilities they should invest in to drive higher performance.BDD in Action: by John Ferguson Smart  Manning Books  BDD in Action teaches you BDD principles and practices and shows you how to integrate them into your  existing development process, no matter what language you use.  First, you&#39;ll apply BDD to requirements analysis so you can focus your development efforts on  underlying business goals.  Then, you&#39;ll discover how to automate acceptance criteria and use tests to guide and report on  the development process.  Along the way, you&#39;ll apply BDD principles at the coding level to write more maintainable and  better documented code.Continuous Delivery: by Jez Humble &amp;amp; David Farley  Purchase  Getting software released to users is often a painful, risky, and time-consuming process. This  groundbreaking new book sets out the principles and technical practices that enable rapid,  incremental delivery of high quality, valuable new functionality to users.Implementing Domain-Driven Design: by Vaughn Vernon  Purchase Links  Implementing Domain-Driven Design presents a top-down approach to understanding domain-driven  design (DDD) in a way that fluently connects strategic patterns to fundamental tactical  programming tools. Vaughn Vernon couples guided approaches to implementation with modern  architectures, highlighting the importance and value of focusing on the business domain while  balancing technical considerations.Paul Hammant Blog  Blog  Call to Arms: Average Story Sizes of One Day  Trunk Based Development  Branch by AbstractionWorking Effectively with Legacy Code by Michael Feathers  Purchase   Is your code easy to change? Can you get nearly instantaneous feedback when you do change it?   Do you understand it? If the answer to any of these questions is no, you have legacy code,   and it is draining time and money away from your development efforts.   In this book, Michael Feathers offers start-to-finish strategies for working more effectively   with large, untested legacy code bases. This book draws on material Michael created for his   renowned Object Mentor seminars: techniques Michael has used in mentoring to help hundreds   of developers, technical managers, and testers bring their legacy systems under control.   The topics covered include   * Understanding the mechanics of software change: adding features, fixing bugs, improving     design, optimizing performance   * Getting legacy code into a test harness   * Writing tests that protect you against introducing new problems   * Techniques that can be used with any language or platformwith examples in Java, C++,     C, and C#   * Accurately identifying where code changes need to be made   * Coping with legacy systems that aren&#39;t object-oriented   * Handling applications that don&#39;t seem to have any structureReferences by TopicArchitectureDelivering quickly goes beyond build automation. Decomposing applications into small, decoupled, individually deployable components is key to rapid feedback.  Architecture Decision Records: A really powerful, lightweight way to document.  12 Factor App  Martin Fowler on Domain Driven Design  Domain Driven Design for Service ArchitectureEstimating StoriesOne of the struggles many teams have is how to break down stories and how to properly estimate work. Heres some resources weve found that have helped us in the past.  Estimating Complexity  BDD with Cynefin - Liz Keogh  BDD and estimation resources  Your stories are too bigEvolutionary DatabaseThe database is just another service and needs to maintain its contract with consumers. Heres some resources on how to get that done.  The 10 Rules of Schema GrowthEvolutionary DevelopmentChanges should be planned to allow daily deployment of the most current code without breaking the current functionality.  Branch by Abstraction  Consumer-driven ContractsFlow ManagementTheres more than one way to manage flow, but all of them take practice and discipline to execute.  Scrum vs. Kanban  Kanban Resources  Scrum Resources  Lean PrinciplesOperational StabilityIs your application ready for production?  Google SRE GuideProduct OwnershipThe role of the Product Owner is commonly misunderstood. Heres a quick video that explains how it works.Source ManagementProper source management is foundational. Everything related to value delivery must be source controlled, including documentation.  Trunk Based Development  Death of Continuous IntegrationStrangler Pattern  Extracting Data Rich ServicesTeamwork  Designing Product Teams  The Infuence of Organizational Structure on Software QualityTesting &amp;amp; QualityDeveloper driven testing is required for CD to function. Heres some resources to get you started and some ideas to help you explore new way to get effective testing done.  FIRST Principles  The Practical Test Pyramid  Code Coverage Targets  Microservice Testing Strategies  Behavior Driven Development  Consumer Driven Contract Testing  Software Testing Cupcake  Resiliency Testing  Just Say No to More End-to-End Tests  Testing in Production  Node Testing Good PracticesFeature Flags  Feature Flags, Toggles, Controls"
 },
 {
  "title": "Sharing",
  "url": "/docs/playbooks/sharing/index.html",
  "content": "SharingThis is WIP"
 },
 {
  "title": "Culture",
  "url": "/docs/playbooks/culture/index.html",
  "content": "Culture  Culture Charter to help team adopt the culture of DevOps  Change Champion NetworkThis is WIP"
 },
 {
  "title": "Work Decomposition",
  "url": "/docs/playbooks/lean/work-decomposition/index.html",
  "content": "Work Decomposition  Behavior Driven Development      "
 },
 {
  "title": "Lean Process",
  "url": "/docs/playbooks/lean/index.html",
  "content": "Lean ProcessThe DevOps L in CALMS is for Lean. Without utilizing Lean principles and process for software delivery, DevOps is lost.The Dojo experience is all about reinforcing Lean principles and practices into the team DNA to enable programs success.The Value Stream  Value Stream Team Orientation  Value Stream Mapping WorkshopApplying Lean Principles  The 7 Lean Principles  The 7 Wastes in Software Development  Cost of DelayHistory of Lean  Deming  Popendiek"
 },
 {
  "title": "Metrics Definitions",
  "url": "/docs/playbooks/metrics/index.html",
  "content": "Metrics DefinitionsMetrics are key to organizational improvement. If we do not measure, then anyattempt at improvement is aimless. Metrics, like any tool, must be usedcorrectly to drive the improvement we need. The following are key delivery metricsand how they can be used and mis-used.CI Execution  Commit Frequency  Build Cycle Time  Average Build DowntimeCD Execution  Throughput          Development Cycle Time      Release Frequency        Stability          Change Failure Rate      Mean Time to Repair      Delivering Quality  Code Coverage  QualityWorkflow Management  Development Cycle Time  Productivity  Lead Time  Work In Process (WIP)"
 },
 {
  "title": "Automation",
  "url": "/docs/playbooks/automation/index.html",
  "content": "AutomationThis is WIP"
 },
 {
  "title": "Agile",
  "url": "/docs/playbooks/agile/index.html",
  "content": "Agile  Agile values and principles  Methodologies  Story Slicing Techniques"
 },
 {
  "title": "Product",
  "url": "/docs/playbooks/product/index.html",
  "content": "Product  Developing a product strategy  Defining business outcomes"
 },
 {
  "title": "Dojo Playbooks",
  "url": "/docs/playbooks/index.html",
  "content": "Dojo PlaybooksThe enclosed playbooks are contributed by multiple Consortium members and reflect the practices of those individual Dojos. They are all wrong in some way, but are the best practices we know currently.Playbooks are focused documents that can be used as a reference by teams wanting to improve how they perform an activity or those helping to coach teams. Each playbook is focused on a single pain point or practice.Recommended PracticesA playbook should follow the following structure:  Definition of what the playbook is trying to accomplish.  A label of the target audience  Recommended, actionable practices that have been found effective.  Tips and tricks that have been found useful in the past.TipsKeep the playbook short enough that it can be consumed quickly. Think 5 minute read, not a novella. Slice if required."
 },
 {
  "title": "Dojo Material",
  "url": "/docs/index.html",
  "content": "Dojo MaterialEnclosed is material used by several Dojos for either direct training or indirect knowledge transfer for their organizations.  Playbooks: Coaching material and suggested practices.  References: Reference material, books, and videos we refer others to."
 },
 {
  "title": "About the Dojo Consortium",
  "url": "/index.html",
  "content": "We are representatives from enterprose dojos who are collaborating to improve both the outcomes of our companies and thequality of life of product teams using immersive learning techniques.Each of the dojos operate in their particular contexts with individualized implementation, but the overall goal is to act as agentsof change to help teams improve the continuous flow of value to the end user.DevOps is often used to mean different things and people new to DevOps often focus on tooling. You cannot buy DevOps and toolsrepresent a small portion of the solution. In our context, this is the guiding principle for DevOps:DevOps should be defined by the outcomes. It is those sets of cultural norms andtechnology practices that enable the fast flow of planned work from, among otherthings, development through tests into operations, while preserving world classreliability, operation, and security. DevOps is not about what you do, but whatyour outcomes are. So many things that we associate with DevOps, such ascommunication and culture, fit underneath this very broad umbrella of beliefsand practices.-- Gene Kim, 2014"
 },
 {
  "title": "Lead Time",
  "url": "/docs/playbooks/metrics/lead-time.html",
  "content": "Lead TimeThis shows the average time it takes for a new request to be delivered. This ismeasured from the creation date to release date for each unit of work and includes Development Cycle Time.What is the intended behavior?Identify over utilized teams, backlogs that need more Product Owner attention,or in conjunction with productivity to help teams optimize their processes.How is it improved?Relentlessly remove old items from the backlog.Improve team processes to reduce Development Cycle Time.Use Innersourcing to allow other teams to help when surges of work arrive.Re-assign, carefully, some components to another team to scale delivery.How is it gamed?  Requests can be tracked in spreadsheet or other locations and then added tothe backlog just before development. This can be identified by decreasedcustomer satisfaction.  Reduce feature refining rigour.When over-driven, what metrics are impacted?  Quality is reduced as less time is spent refining and defininghow to validate the feature.  Productivity is reduced if tightly coupled components areshifted to another team or excessive communication is required forReferences  InnerSourcing."
 },
 {
  "title": "MTTR",
  "url": "/docs/playbooks/metrics/mean-time-to-repair.html",
  "content": "MTTRMean Time to Repair is the average time between when a incidents isdetected and when it is resolved.Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time.What is the intended behavior?Improve the ability to more rapidly resolve system instability and service outages.How is it improved?  Make sure the pipeline alway deployable.  Keep build cycle time short to allow roll-forward.  Implement feature flags for larger feature changes to allow the them to be deactivated without re-deploying.  Identify stability issues and prioritize them in the backlog.How is it gamed?  Updating support incidents to closed before service is restored.When over-driven, what metrics are impacted?  Quality decreases as issues re-occur due to lack of root causefixes.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate"
 },
 {
  "title": "Productivity",
  "url": "/docs/playbooks/metrics/productivity.html",
  "content": "ProductivityThroughput per week. This is measured by how manyitems were finished as a trend over time. This includes all items,defects and story work.What is the intended behavior?Help teams find what level of throughput per week is consistently achievable and find ways to increase this over time by reducing waste, reducing toil, improving planning, and focusing on teamwork.How is it improved?  Smaller stories are easier to understand and deliver.  Minimize hard dependencies. Each hard dependency reduces the odds of on-timedelivery by 50%.  Swarm stories so that the team is working as a unit to deliver faster.How is it gamed?  More, smaller tasks.  Cherry pick easy, low priority items.  Skip quality steps.  Prematurely sign-off work only to have defects reported later.When over-driven, what metrics are impacted?  Quality defect ratio goes up as more defects are reported.  WIP increases as teams start more work to look morebusy.ReferencesHarvard Business Review: Six Myths of Product Development"
 },
 {
  "title": "Quality",
  "url": "/docs/playbooks/metrics/quality.html",
  "content": "QualityQuality is measured as the percentage of finished work that is reported as a defect by the end user.What is the intended behavior?Identify and rapidly resolve any gaps in the upstream quality steps starting at understanding and refining the product requirements.How is it improved?  Identify root cause.  Add automated checks to the pipeline to prevent re-occurrence.How is it gamed?  Defects are entered as additional stories (seen by growing throughput, butlowering customer satisfaction and complaints)When over-driven, what metrics are impacted?  WIP metric increases for defect types.  Feature delivery is impacted as defects are over prioritized."
 },
 {
  "title": "Release Frequency",
  "url": "/docs/playbooks/metrics/release-frequency.html",
  "content": "Release FrequencyHow frequently the team releases changes to production. This isaveraged by team size (deploys / day / developer) to achieve lowest common denominator comparisons.Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time.What is the intended behavior?Small changes deployed very frequently to exercise the ability to fix productionrapidly, reduce MTTR, and accelerate value delivery.How is it improved?  Reduce Development Cycle Time.  Remove handoffs to other teams.  Remove manual or external approvals for change.  Move hard dependencies to soft dependencies with feature flags and contract tests.How is it gamed?  Re-deploying the same artifact repeatedly.  Building new artifacts that contain no changes.When over-driven, what metrics are impacted?  Change Fail Rate increases.  Quality decreases.Recommended Practices  Trunk Based Development  Continuous Integration  Feature FlaggingReferences  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate."
 },

 {
  "title": "Training",
  "url": "/training.html",
  "content": "# {{ page.title }}&gt; Check out the [slides](./training/dojo-overview.html)"
 },
 {
  "title": "Value Stream Orientation",
  "url": "/docs/playbooks/lean/value-stream-orientation.html",
  "content": "# {{ page.title }}## IntroductionOne of the most important coaching goals in a Dojo challenge is to inspire the team to understand the system view, specifically how value flows from ideation all the way to deployment and support. It isn&#39;t the &quot;First Way&quot; of DevOps for nothing. However, the question we often get sounds something like:&gt; Is it really necessary to train everyone regarding the overall system? Our developers need to be heads down and let the architects, RTE&#39;s, and other Program leaders manage the big picture.Of course as you read that question you can easily detect it resembles a defense of a well established management paradigm. Broaching this subject in your Dojo will require a healthy combination of some of these organizational attributes:* Understanding that DevOps is more than just pipeline tooling skills.* Sufficient framing and preparation with managers that the team will be empowered toward autonomy while entrusted to the Dojo.* Trust that the Dojo coaches are working toward the good of all, not just the team members.* Openness that despite how teams are currently aligned, that teams can contribute realignment insights to improve feature lead times. * A catching on of the fact that software architecture is a skill vs being a role.Even heavily matrixed organizations mired in a negative cycle of pointing people&#39;s attention back toward their siloed constraints are coming around to the realization that they must at least make the Value Stream visible in some way. We beleive the Dojo can demonstrate value to both the team and the programs they serve by establishing a Value Stream orientation in the early stages of the engagement. We map the value stream early on. We call out dependencies. We reduce handoffs where empowered. We report on the waste in handoffs where not empowered. In all this, we see time and time again that Value Stream orientation in the Dojo creates retained value for the team and creates viral value for other programs in the organization watching all this transpire. "
 },
 {
  "title": "Value Stream Mapping Workshop",
  "url": "/docs/playbooks/lean/wm-vsm.html",
  "content": "# {{ page.title }}The purpose of Value Stream Mapping Workshop is to understand all of the steps needed todeliver value from conception to production. We can then use it as a tool toidentify constraints and propose improvements to the value stream.## Recommended Practices1. Everyone who has a touch point in the value stream should be present for the   exercise. This includes, but is not limited to, the developers, the   engineering manager, the product owner, and representatives from any external   teams that have required steps between idea and production.2. Start with an introduction to what value stream mapping is, and why it is important.### Explain the terms associated with value stream mapping- Build Cycle Time: Total duration of the build, from commit to deploy.- Development Cycle Time: The time from when work begins until it is deployed to production. Done.- Lead Time: The time taken from start to end of the value stream.- Process Time / Value Add Time: The time spent executing a particular process.- Wait Time / Non-value Time: The time between processes where no activity is occurring.- Percent Complete and Accurate: The percentage of work from a process that is   rejected by the next process. If coding fails code review 20% of the time,   it&#39;s %C/A is 80%.### Identify source of request*Example:* Refine EpicFor each source of _Requests_  1. What is the outcome of that step, or next step?  2. Who is involved in that step?  3. How long does this step take?  4. How long between the previous and current steps?### Identify Rework Loops for each step1. To which steps do we return to from this one for corrections?2. How often is work rejected from this step (percentage complete and accurate)?### Identify value added time, cycle time, and lead time1. What is the total value time (time spent doing work) from conception to production?2. What is the total non-value time (time waiting) from conception to production?## Outcomes- Visual representation of the value stream(s) of the team.- Identify possible constraints to flow based on value added time, cycle time, and lead time.## Sample Workshop AgendaThe below sample is for a 3 day workshop that focuses more on the flow of work and less on the numbers.  If you would like to go into more of the metrics extending the workshop to 5 days would allow for that.#### Day 1- Workshop working agreements- Review of workshop charter- Create/interate through current state value stream map#### Day 2- Refine Value Stream Map and add data points- Identify waste and oppotunities to improve the flow of work- Start future sate value stream map#### Day 3- Complete future state value stream map- Document/prioritize Kiazen improvement opportunities## Tips- Involve all team members associated to any part of the process of getting value from conception to production.- Review and maintain value stream map to show wins associated to implementing improvement.- Take into account all potential flows for team processes, and value stream those as well.## ValueAs a team, we want to understand how to value stream map our team processes, so that we may understand bottlenecks associated to delivering value, and identify areas of improvement.## Acceptance Criteria- Value stream all things associated to delivering value.- Create action items of improvement from exercise.## References- [Value Stream Mapping Guide](https://creately.com/blog/diagrams/value-stream-mapping-guide/)- [Value Stream Mapping: How to Visualize Work and Align Leadership for Organizational Transformation](https://books.google.com/books/about/Value_Stream_Mapping_How_to_Visualize_Wo.html?id=MeFrAAAAQBAJ)"
 },
 {
  "title": "WIP",
  "url": "/docs/playbooks/metrics/work-in-progress.html",
  "content": "# {{ page.title }}Work in Process (WIP) is the total work that has been started but notcompleted. This includes **all** work, defects, tasks, stories, etc.### What is the intended behavior?Teams should limit WIP and work together to complete WIP items in preference tostarting new work.Use WIP limits to identify and exploit constraints in the [Development Cycle Time](./development-cycle-time.html).### How is it improved?- The team should focus on finishing items closest to being ready for  production.- Set and do not exceed WIP limits for the team and for each step.  - WIP limit guidance: 2N-1 where N is the number of team members capable of doing the work.- Keep the Kanban board visible at all times.### How is it gamed?- Teams can update incomplete work to &quot;done&quot; before all quality steps have been  completed.- Reduce the pace of starting new work without focusing on helping to complete  WIP.### When over-driven, what metrics are impacted?- [Quality](./quality.html) metric decreases as additional defects are reported.- [Productivity](./productivity.html) metric decreases."
 },

{
  "title": "Great change happens through small steps. A lot of them.",
  "url": "/blog/2019-09-07-cgallivan.html",
  "date": "2019-09-07 00:00:00 +0000",
  "content": "&amp;lt;img src=../assets/img/posts/6D524680-10E0-4BB5-ACE5-558A6C96E06B.pngwidth=90%alt=Post from Instagram: https://www.instagram.com/p/By0MZGPlsS1/?igshid=lhif13zps1la&amp;gt;The DevOps community provides sage advice to focus on outcomes. Outcomes in this context serve as the North Star to guide our improvement journey.For some of us focusing on outcomes can be daunting, especially when that outcome is so far away. If we are not careful, we can get lost in the minutia; stuck in the starters block. How do we get out of the starters block? I always tell my teams to make each day a little bit better than the day before. Make a small, simple improvement every day.Remember every successful journey starts with a single stepand ends with tired legs.This post originally appeared on Instagram. You can see other posts @the.devops.hive there"
 },{
  "title": "5 Minute DevOps - GitFlow Best Practices",
  "url": "/blog/2019-09-07-bfinster.html",
  "date": "2019-09-07 00:00:00 +0000",
  "content": "I was asked recently about the best practice for using GitFlow with continuous integration. For those who do not know, this is GitFlow:There is no CI good practice that includes GitFlow. For continuous integration to meet the definition, these are the good practices:  Developers must implement all tests before they commit code. This is a non-negotiable and I will not work with developers who refuse to test. Professionals deliver working, tested code. Script kiddies dont test.  Use CI automation to trigger builds for every pull request so that bad changes can be rejected before code review.  Ensure that all tests are executed and linting and static code analysis is done for every PR.  Implement CI practices:          All developers branch from the trunk, make changes, and submit PRs back to trunk.      The branches are removed in less than 24 hours.      Youre now doing Trunk Based Development. Welcome to your CI/CD journey!The complexity of the CI automation will depend on how poorly the application is architected and the size of the development team. Monoliths with poor sub-domain boundaries will require much more complicated test design and test execution will take much longer. Evolve The architecture into independent, loosely coupled sub-domains to improve delivery speed, reduce testing overhead, and improve stability, resilience, and scalability.GitFlow does not increase quality or value delivery. It delays quality signal feedback to the developers, incentivizes manual process, and is incredibly wasteful of time and resources. No modern development uses it.Some developers have a religion built around GitFlow because it reduces typing (reduced pain from not testing) and they dont track their levels of re-work, lost changes, or conflict resolution. In 2010, GitFlow felt good. We could keep Master clean. That was almost a decade ago. Testing was still mostly manual. We were still on Java 6. NodeJS was barely a thing. Time to modernize. We dont keep Master clean with process. We keep it clean with automation.Other examples:  The Amazing DevOps Transformation Of The HP LaserJet Firmware Team  What is Continuous Delivery?This post orginally appeared on Medium. You can see other posts in the 5 Minute DevOps series there"
 },
 {
  "title": "",
  "url": "",
  "date": "",
  "content": ""
 }
]