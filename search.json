[

 {
  "title": "Average Build Downtime",
  "url": "/docs/metrics/average-build-downtime.html",
  "content": "Average Build DowntimeThe average length of time between when a build breaks and when it is fixed.What is the intended behavior?Decrease the average time to recover from a broken build.How is it improved?  Refactor to improve testability and modularity.  Improve tests to locate problems more rapidly.  Decrease the size of the component to reduce complexity.  Add automated alerts for broken builds.How is it gamed?  Re-build the previous version.  Remove tests that are failing.When over-emphasized, what metrics are impacted?  Commit frequency decreases as additional manual or automated process overhead is added before integration to master.  Productivity decreases as manual verification steps are added to ensure each pull request does not break the build."
 },
 {
  "title": "Blog",
  "url": "/blog.html",
  "content": "Latest Posts        Demo    Example blog post intro    "
 },
 {
  "title": "Build Cycle Time",
  "url": "/docs/metrics/build-cycle-time.html",
  "content": "Build Cycle TimeThe time from code commit to production deploy. This is the minimum time changes can be applied to production.What is the intended behavior?Reduce pipeline duration to improve MTTR and toamplify feedback loops.How is it improved?  Identify areas of the build that can run concurrently.  Replace integration tests in the pipeline with virtual services and move integration testing to an asynchronous process.  Remove unneeded code.  Break down large services into smaller domains.How is it gamed?  Reduce the number of tests running or test types executed.When over-driven, what metrics are impacted?  Quality decreases if testing steps are skipped."
 },
 {
  "title": "Change Fail Rate",
  "url": "/docs/metrics/change-fail-rate.html",
  "content": "Change Fail RateThe percentage of changes that result in negative customer impact, system degradation, or rollback.changeFailRate = impactingChangeCount / changeCountSoftware delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time and Release Frequency for Deploy Frequency.What is the intended behavior?Reduce the percentage of failed changes to less than 15%.How is it improved?  Release more, smaller changes to increase the odds of success and reduce the impact of failure.  Identify root cause for each failure and improve the automated quality checks.How is it gamed?  Deploy fixes without recording the defect.  Create defect review meetings and re-classify defects as feature requests.  Re-deploy the latest working version to increase deploy count.When over-driven, what metrics are impacted?  Deploy frequency decreases as focus is placed on zero defect changes.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate"
 },
 {
  "title": "Code Coverage",
  "url": "/docs/metrics/code-coverage.html",
  "content": "Code CoverageMeasure of how many lines, branches, and functions are executed when automated tests are run. Industry average is ~80%.What is the intended behavior?Provide the information needed to identify risky or complicated portions of the code that are not sufficiently covered by tests.How is it improved?  Write tests for code that SHOULD be covered that isnt.  Refactor the application to improve testability.How is it gamed?  Tests are written for code that receives no value from testing.  Test code is written that does not check for failures.  Code is inappropriately excluded from test coverage reporting.Example: The following test will result in 100% function, branch, and line coverage with no behavior tested./* Returns the sum of two integers *//* Returns NaN for non-integers */function addWholeNumbers(a, b) {  if (a % 1 === 0 &amp;amp;&amp;amp; b % 1 === 0) {    return a + b;  } else {    return NaN;  }}it(&#39;Should add two whole numbers&#39; () =&amp;gt; {  expect(addWholeNumbers(2, 2)).to.not.be.NaN;  expect(addWholeNumbers(1.1, 0)).to.not.be.null;})The following will report the same code coverage resultsit(&#39;Should add two whole numbers&#39; () =&amp;gt; {  addWholeNumbers(2, 2)  addWholeNumbers(1.1, 0)})When over-driven, what metrics are impacted?  Development Cycle Time increases with additional development time dedicated to chasing the coverage metric.  Quality decreases as poor quality tests hide lack of real codecoverage."
 },
 {
  "title": "Coming soon",
  "url": "/docs/playbooks/coming-soon.html",
  "content": "Coming soonOh yeah, were working on it!"
 },
 {
  "title": "Commit Frequency",
  "url": "/docs/metrics/commit-frequency.html",
  "content": "Commit FrequencyThe average frequency each developer on a team integrates tested, non-breaking code to trunk / master. Target is more than once perday per developer to reduce the size of change and speed value delivery.What is the intended behavior?  Increase the frequency of code integration.  Reduce the size of each change.  Improve code review processes.How is it improved?  Decompose code changes into smaller, non-breaking changes that are eventually feature complete.  Use Behavior Driven Development to aid functional breakdown.  Use TDD to design more modular code that can be integrated more frequently.  Make new code reachable only by the tests or flagged off for otherenvironments with feature flags.How is it gamed?  Meaningless changes integrated to trunk.When over-driven, what metrics are impacted?  Quality decreases when testing is skipped.  Development Cycle Time increases due to additionalreview overhead.Recommended Practices  Trunk Based Development  Continuous Integration  Feature Flagging"
 },
 {
  "title": "Deploy Frequency",
  "url": "/docs/metrics/deploy-frequency.html",
  "content": "Deploy FrequencyHow frequently the team deploys to production. This isaveraged by team size (deploys / day / developer).Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time and Release Frequency for Deploy Frequency.What is the intended behavior?Small changes deployed very frequently to exercise the ability to fix productionrapidly and reduce MTTR.How is it improved?  Reduce Development Cycle Time.  Remove handoffs to other teams.  Remove manual or external approvals for change.  Move hard dependencies to soft dependencies with feature flags and contract tests.How is it gamed?  Re-deploying the same artifact repeatedly.  Building new artifacts that contain no changes.When over-driven, what metrics are impacted?  Change Fail Rate increases.  Quality decreases.Recommended Practices  Trunk Based Development  Continuous Integration  Feature FlaggingReferences  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate."
 },
 {
  "title": "Development Cycle Time",
  "url": "/docs/metrics/development-cycle-time.html",
  "content": "Development Cycle TimeThe average time from identifying a unit of work as Ready to Start to Production. Target average time is less than 60 minutes.Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time and Release Frequency for Deploy Frequency.What is the intended behavior?Reduce the time it takes to deliver refined work to production.How is it improved?  Decompose work so it can be delivered in smaller increments and by more team members.  Identify and remove process waste, handoffs, and delays in the construction process.  Improve testing efficiency for more rapid feedback loops.  Automate and standardize the build.How is it gamed?  Move things to Done status that are not in production.  Move items directly from Backlog to Done after deploying to production.  Split work into tasks that must be completed before work can be delivered (development task, testing task,etc.).When over-driven, what metrics are impacted?  Quality decreases as quality processes are skipped.  Change fail rate increases.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. Accelerate"
 },
 {
  "title": "References",
  "url": "/docs/references/index.html",
  "content": "ReferencesContinuous Delivery isnt new. Its been commonplace in many companies for over a decade. Included here is a list of informationresources weve found helpful as weve continued to improve.  References          Microservices      Understanding DevOps      Continuous Integration      Continuous Delivery      Domain Driven Design      TDD/BDD      Pair Programming      Suggested Reading                  Accelerate: by Nicole Forsgren, Jez Humble, &amp;amp; Gene Kim          BDD in Action: by John Ferguson Smart          Continuous Delivery: by Jez Humble &amp;amp; David Farley          Implementing Domain-Driven Design: by Vaughn Vernon          Paul Hammant Blog          Working Effectively with Legacy Code by Michael Feathers                    References by Topic                  Architecture          Estimating Stories          Evolutionary Database          Evolutionary Development          Flow Management          Operational Stability          Product Ownership          Source Management          Strangler Pattern          Teamwork          Testing &amp;amp; Quality                    Feature Flags      Microservices  Microservices Architectural Design Patterns PlaybookUnderstanding DevOps  Understanding DevopsContinuous Integration  Continuous Integration  Integration TestingContinuous Delivery  Continuous Integration Big Picture  Implementing Continuous Delivery  Docker Ansible Continuous Delivery  Continuous-Database-DeliveryDomain Driven Design  Domain Driven Design Fundamentals  Domain Driven Design In Practice  Domain Driven Design Legacy Projects  Modern Software ArchitectureTDD/BDD  Test First Development Part-1  Test First Development Part-2  Outside In TDD  Test Driven Development Big Picture  Pragmatic-BDD-Dotnet  Clean Architecture Patterns  Pragmatic-Unit-Testing  TDD Junit5  TDD As Design Tool  Play By Play Wilson TDDPair Programming  Pair ProgrammingSuggested ReadingAccelerate: by Nicole Forsgren, Jez Humble, &amp;amp; Gene Kim  Purchase  Does technology actually matter? And how can we apply technology to drive business value?  For years, we&#39;ve been told that the performance of software delivery teams doesn&#39;t matter;  that it can&#39;t provide a competitive advantage to our companies.  Through four years of groundbreaking research, Dr. Nicole Forsgren, Jez Humble, and  Gene Kim set out to find a way to measure software delivery performanceand what drives  it, using rigorous statistical methods. This book presents both the findings and the  science behind that research. Readers will discover how to measure the performance of  their teams, and what capabilities they should invest in to drive higher performance.BDD in Action: by John Ferguson Smart  Manning Books  BDD in Action teaches you BDD principles and practices and shows you how to integrate them into your  existing development process, no matter what language you use.  First, you&#39;ll apply BDD to requirements analysis so you can focus your development efforts on  underlying business goals.  Then, you&#39;ll discover how to automate acceptance criteria and use tests to guide and report on  the development process.  Along the way, you&#39;ll apply BDD principles at the coding level to write more maintainable and  better documented code.Continuous Delivery: by Jez Humble &amp;amp; David Farley  Purchase  Getting software released to users is often a painful, risky, and time-consuming process. This  groundbreaking new book sets out the principles and technical practices that enable rapid,  incremental delivery of high quality, valuable new functionality to users.Implementing Domain-Driven Design: by Vaughn Vernon  Purchase Links  Implementing Domain-Driven Design presents a top-down approach to understanding domain-driven  design (DDD) in a way that fluently connects strategic patterns to fundamental tactical  programming tools. Vaughn Vernon couples guided approaches to implementation with modern  architectures, highlighting the importance and value of focusing on the business domain while  balancing technical considerations.Paul Hammant Blog  Blog  Call to Arms: Average Story Sizes of One Day  Trunk Based Development  Branch by AbstractionWorking Effectively with Legacy Code by Michael Feathers  Purchase   Is your code easy to change? Can you get nearly instantaneous feedback when you do change it?   Do you understand it? If the answer to any of these questions is no, you have legacy code,   and it is draining time and money away from your development efforts.   In this book, Michael Feathers offers start-to-finish strategies for working more effectively   with large, untested legacy code bases. This book draws on material Michael created for his   renowned Object Mentor seminars: techniques Michael has used in mentoring to help hundreds   of developers, technical managers, and testers bring their legacy systems under control.   The topics covered include   * Understanding the mechanics of software change: adding features, fixing bugs, improving     design, optimizing performance   * Getting legacy code into a test harness   * Writing tests that protect you against introducing new problems   * Techniques that can be used with any language or platformwith examples in Java, C++,     C, and C#   * Accurately identifying where code changes need to be made   * Coping with legacy systems that aren&#39;t object-oriented   * Handling applications that don&#39;t seem to have any structureReferences by TopicArchitectureDelivering quickly goes beyond build automation. Decomposing applications into small, decoupled, individually deployable components is key to rapid feedback.  Architecture Decision Records: A really powerful, lightweight way to document.  12 Factor App  Martin Fowler on Domain Driven Design  Domain Driven Design for Service ArchitectureEstimating StoriesOne of the struggles many teams have is how to break down stories and how to properly estimate work. Heres some resources weve found that have helped us in the past.  Estimating Complexity  BDD with Cynefin - Liz Keogh  BDD and estimation resources  Your stories are too bigEvolutionary DatabaseThe database is just another service and needs to maintain its contract with consumers. Heres some resources on how to get that done.  The 10 Rules of Schema GrowthEvolutionary DevelopmentChanges should be planned to allow daily deployment of the most current code without breaking the current functionality.  Branch by Abstraction  Consumer-driven ContractsFlow ManagementTheres more than one way to manage flow, but all of them take practice and discipline to execute.  Scrum vs. Kanban  Kanban Resources  Scrum Resources  Lean PrinciplesOperational StabilityIs your application ready for production?  Google SRE GuideProduct OwnershipThe role of the Product Owner is commonly misunderstood. Heres a quick video that explains how it works.If you have questions about this information or or suggestions for improvement, please contact us at #devops-dojo.Source ManagementProper source management is foundational. Everything related to value delivery must be source controlled, including documentation.  Trunk Based Development  Death of Continuous IntegrationStrangler Pattern  Extracting Data Rich ServicesTeamwork  Designing Product Teams  The Infuence of Organizational Structure on Software QualityTesting &amp;amp; QualityDeveloper driven testing is required for CD to function. Heres some resources to get you started and some ideas to help you explore new way to get effective testing done.  FIRST Principles  The Practical Test Pyramid  Code Coverage Targets  Microservice Testing Strategies  Behavior Driven Development  Consumer Driven Contract Testing  Software Testing Cupcake  Resiliency Testing  Just Say No to More End-to-End Tests  Testing in Production  Node Testing Good PracticesFeature Flags  Feature Flags, Toggles, Controls"
 },
 {
  "title": "Metrics Definitions",
  "url": "/docs/metrics/index.html",
  "content": "Metrics DefinitionsMetrics are key to organizational improvement. If we do not measure, then anyattempt at improvement is aimless. Metrics, like any tool, must be usedcorrectly to drive the improvement we need. The following are important metrics,and how they can be used and mis-used.CI Execution  Commit Frequency  Build Cycle Time  Average Build DowntimeCD Execution  Throughput          Development Cycle Time      Deploy Frequency        Stability          Change Failure Rate      Mean Time to Repair      Delivering Quality  Code Coverage  QualityWorkflow Management  Development Cycle Time  Productivity  Total Lead Time  Work In Process (WIP)"
 },
 {
  "title": "Sharing",
  "url": "/docs/playbooks/sharing/index.html",
  "content": "SharingThis is WIP"
 },
 {
  "title": "Culture",
  "url": "/docs/playbooks/culture/index.html",
  "content": "Culture  Culture Charter to help team adopt the culture of DevOps  Change Champion NetworkThis is WIP"
 },
 {
  "title": "Lean Process",
  "url": "/docs/playbooks/lean/index.html",
  "content": "Lean ProcessThe DevOps L in CALMS is for Lean. Without utilizing Lean principles and process for software delivery, DevOps is lost.The Dojo experience is all about reinforcing Lean principles and practices into the team DNA to enable programs success.The Value Stream  Value Stream Team Orientation  Value Stream Mapping WorkshopApplying Lean Principles  The 7 Lean Principles  The 7 Wastes in Software Development  Cost of DelayHistory of Lean  Deming  Popendiek"
 },
 {
  "title": "Metrics",
  "url": "/docs/playbooks/metrics/index.html",
  "content": "MetricsThe right metrics used the right way in the right combination are key to improvement.This is WIP"
 },
 {
  "title": "Automation",
  "url": "/docs/playbooks/automation/index.html",
  "content": "AutomationThis is WIP"
 },
 {
  "title": "Agile",
  "url": "/docs/playbooks/agile/index.html",
  "content": "Agile  Agile values and principles  Methodologies  Story Slicing Techniques"
 },
 {
  "title": "Product",
  "url": "/docs/playbooks/product/index.html",
  "content": "Product  Developing a product strategy  Defining business outcomes"
 },
 {
  "title": "Dojo Playbooks",
  "url": "/docs/playbooks/index.html",
  "content": "Dojo PlaybooksThe enclosed playbooks are contributed by multiple Consortium members and reflect the practices of those individual Dojos. They are all wrong in some way, but are the best practices we know currently.Playbooks are focused documents that can be used as a reference by teams wanting to improve how they perform an activity or those helping to coach teams. Each playbook is focused on a single pain point or practice.Recommended PracticesA playbook should follow the following structure:  Definition of what the playbook is trying to accomplish.  A label of the target audience  Recommended, actionable practices that have been found effective.  Tips and tricks that have been found useful in the past.TipsKeep the playbook short enough that it can be consumed quickly. Think 5 minute read, not a novella. Slice if required."
 },
 {
  "title": "Dojo Material",
  "url": "/docs/index.html",
  "content": "Dojo MaterialEnclosed is material used by several Dojos for either direct training or indirect knowledge transfer for their organizations.  Playbooks: Coaching material and suggested practices.  References: Reference material, books, and videos we refer others to."
 },
 {
  "title": "About the DevOps Dojo Consortium",
  "url": "/overview/index.html",
  "content": "We are a collaboration of enterprise Dojos all seeking to improve both the outcomes of their companies and thequality of life of product teams.DevOps is often used to mean different things and people new to DevOps often focus on tooling. You cannot buy DevOps and tools represent a small portion of the solution. In our context, this is guiding principle for DevOpsDevOps should be defined by the outcomes. It is those sets of cultural norms andtechnology practices that enable the fast flow of planned work from, among otherthings, development through tests into operations, while preserving world classreliability, operation, and security. DevOps is not about what you do, but whatyour outcomes are. So many things that we associate with DevOps, such ascommunication and culture, fit underneath this very broad umbrella of beliefsand practices.-- Gene Kim, 2014Each of the Dojos operate in their particular contexts with individualized implementation, but the overall goal is improving thecontinuous flow of value to the end user with people collaborating with lean processes and heavy automation."
 },
 {
  "title": "About the DevOps Dojo Consortium",
  "url": "/index.html",
  "content": "We are a collaboration of enterprise Dojos all seeking to improve both the outcomes of their companies and thequality of life of product teams.DevOps is often used to mean different things and people new to DevOps often focus on tooling. You cannot buy DevOps and tools represent a small portion of the solution. In our context, this is guiding principle for DevOpsDevOps should be defined by the outcomes. It is those sets of cultural norms andtechnology practices that enable the fast flow of planned work from, among otherthings, development through tests into operations, while preserving world classreliability, operation, and security. DevOps is not about what you do, but whatyour outcomes are. So many things that we associate with DevOps, such ascommunication and culture, fit underneath this very broad umbrella of beliefsand practices.-- Gene Kim, 2014Each of the Dojos operate in their particular contexts with individualized implementation, but the overall goal is improving thecontinuous flow of value to the end user with people collaborating with lean processes and heavy automation."
 },
 {
  "title": "MTTR",
  "url": "/docs/metrics/mean-time-to-repair.html",
  "content": "MTTRMean Time to Repair is the average time between when a service outage isdetected and when it is resolved. Target average time is less than 60 minutes.Software delivery performance is a combination of three metrics: lead time, release frequency, and MTTR. Change fail rate is not included, though it is highly correlated.Accelerate uses Lead Time for Development Cycle Time and Release Frequency for Deploy Frequency.What is the intended behavior?Reduce system instability and service outage time.How is it improved?  Always make sure the pipeline is green and ready to deploy.  Keep build cycle time short to allow roll-forward.  Implement feature flags for risky changes to allow the changes to be deactivated without re-deploying.  Identify stability issues and prioritize them in the backlog.How is it gamed?  Updating support incidents to closed before service is restored.When over-driven, what metrics are impacted?  Quality decreases as issues re-occur due to lack of root causefixes.References  Nicole Forsgren PhD, Jez Humble &amp;amp; Gene Kim. AccelerateBack To Bifrost"
 },
 {
  "title": "Productivity",
  "url": "/docs/metrics/productivity.html",
  "content": "ProductivityThroughput per week. This is measured by how manyitems were finished as a trend over time. This includes all items,defects and story work.What is the intended behavior?Help teams find what level of throughput per week is consistently achievable andto find ways to increase this over time by improving their processes.How is it improved?  Smaller stories are easier to understand and deliver.  Minimize hard dependencies. Each hard dependency reduces the odds of on-timedelivery by 50%.  Swarm stories so that the team is working as a unit to deliver faster.How is it gamed?  More, smaller tasks.  Cherry pick easy, low priority items.  Skip quality steps.  Prematurely sign-off work only to have defects reported later.When over-driven, what metrics are impacted?  Quality defect ratio goes up as more defects are reported.  WIP increases as teams start more work to look morebusy.ReferencesHarvard Business Review: Six Myths of Product Development"
 },
 {
  "title": "Quality",
  "url": "/docs/metrics/quality.html",
  "content": "QualityQuality is measured as the percentage of finished work that is marked as defecttype for the reporting period.What is the intended behavior?Help teams continuously triage and complete defect backlog items at a consistentrate. Try and drive this percentage lower without deferring defects.How is it improved?  Identify root cause.  Add tests to prevent root cause.  Review the team quality process and look for improvement items.How is it gamed?  Defects are entered as additional stories (seen by growing throughput, butlowering customer satisfaction and complaints)When over-driven, what metrics are impacted?  WIP metric increases for defect types.  Feature delivery is impacted as defects are over prioritized."
 },

 {
  "title": "Total Lead Time",
  "url": "/docs/metrics/total-lead-time.html",
  "content": "# {{ page.title }}This shows the average time it takes for a new request to be delivered. This ismeasured from the creation date to release date for each unit of work and includes [Development Cycle Time](./development-cycle-time.html).### What is the intended behavior?Identify over utilized teams, backlogs that need more Product Owner attention,or in conjunction with [productivity](./productivity.html) to help teams optimize their processes.### How is it improved?Relentlessly remove old items from the backlog.Improve team processes to reduce [Development Cycle Time](./development-cycle-time.html).Use InnerSourcing to offload work on to teams with capacity.Reallocate capability ownership to another team.### How is it gamed?- Requests can be tracked in spreadsheet or other locations and then added to  the backlog just before development. This can be identified by decreased  customer satisfaction.- Reduce feature refining rigour.### When over-driven, what metrics are impacted?- [Quality](./quality.html) is reduced as less time is spent refining and defining  how to validate the feature.- [Productivity](./productivity.html) is reduced if tightly coupled components are  shifted to another team or excessive communication is required for  [InnerSourcing](https://paypal.github.io/InnerSourceCommons/)."
 },
 {
  "title": "Training",
  "url": "/training.html",
  "content": "# {{ page.title }}&gt; Check out the [slides](./training/dojo-overview.html)"
 },
 {
  "title": "Value Stream Orientation",
  "url": "/docs/playbooks/lean/value-stream-orientation.html",
  "content": "# {{ page.title }}## IntroductionOne of the most important coaching goals in a Dojo challenge is to inspire the team to understand the system view, specifically how value flows from ideation all the way to deployment and support. It isn&#39;t the &quot;First Way&quot; of DevOps for nothing. However, the question we often get sounds something like:&gt; Is it really necessary to train everyone regarding the overall system? Our developers need to be heads down and let the architects, RTE&#39;s, and other Program leaders manage the big picture.Of course as you read that question you can easily detect it resembles a defense of a well established management paradigm. Broaching this subject in your Dojo will require a healthy combination of some of these organizational attributes:* Understanding that DevOps is more than just pipeline tooling skills.* Sufficient framing and preparation with managers that the team will be empowered toward autonomy while entrusted to the Dojo.* Trust that the Dojo coaches are working toward the good of all, not just the team members.* Openness that despite how teams are currently aligned, that teams can contribute realignment insights to improve feature lead times. * A catching on of the fact that software architecture is a skill vs being a role.Even heavily matrixed organizations mired in a negative cycle of pointing people&#39;s attention back toward their siloed constraints are coming around to the realization that they must at least make the Value Stream visible in some way. We beleive the Dojo can demonstrate value to both the team and the programs they serve by establishing a Value Stream orientation in the early stages of the engagement. We map the value stream early on. We call out dependencies. We reduce handoffs where empowered. We report on the waste in handoffs where not empowered. In all this, we see time and time again that Value Stream orientation in the Dojo creates retained value for the team and creates viral value for other programs in the organization watching all this transpire. "
 },
 {
  "title": "Value Stream Mapping Workshop",
  "url": "/docs/playbooks/lean/wm-vsm.html",
  "content": "# {{ page.title }}The purpose of Value Stream Mapping Workshop is to understand all of the steps needed todeliver value from conception to production. We can then use it as a tool toidentify constraints and propose improvements to the value stream.## Recommended Practices1. Everyone who has a touch point in the value stream should be present for the   exercise. This includes, but is not limited to, the developers, the   engineering manager, the product owner, and representatives from any external   teams that have required steps between idea and production.2. Start with an introduction to what value stream mapping is, and why it is important.### Explain the terms associated with value stream mapping- Build Cycle Time: Total duration of the build, from commit to deploy.- Development Cycle Time: The time from when work begins until it is deployed to production. Done.- Lead Time: The time taken from start to end of the value stream.- Process Time / Value Add Time: The time spent executing a particular process.- Wait Time / Non-value Time: The time between processes where no activity is occurring.- Percent Complete and Accurate: The percentage of work from a process that is   rejected by the next process. If coding fails code review 20% of the time,   it&#39;s %C/A is 80%.### Identify source of request*Example:* Refine EpicFor each source of _Requests_  1. What is the outcome of that step, or next step?  2. Who is involved in that step?  3. How long does this step take?  4. How long between the previous and current steps?### Identify Rework Loops for each step1. To which steps do we return to from this one for corrections?2. How often is work rejected from this step (percentage complete and accurate)?### Identify value added time, cycle time, and lead time1. What is the total value time (time spent doing work) from conception to production?2. What is the total non-value time (time waiting) from conception to production?## Outcomes- Visual representation of the value stream(s) of the team.- Identify possible constraints to flow based on value added time, cycle time, and lead time.## Sample Workshop AgendaThe below sample is for a 3 day workshop that focuses more on the flow of work and less on the numbers.  If you would like to go into more of the metrics extending the workshop to 5 days would allow for that.#### Day 1- Workshop working agreements- Review of workshop charter- Create/interate through current state value stream map#### Day 2- Refine Value Stream Map and add data points- Identify waste and oppotunities to improve the flow of work- Start future sate value stream map#### Day 3- Complete future state value stream map- Document/prioritize Kiazen improvement opportunities## Tips- Involve all team members associated to any part of the process of getting value from conception to production.- Review and maintain value stream map to show wins associated to implementing improvement.- Take into account all potential flows for team processes, and value stream those as well.## ValueAs a team, we want to understand how to value stream map our team processes, so that we may understand bottlenecks associated to delivering value, and identify areas of improvement.## Acceptance Criteria- Value stream all things associated to delivering value.- Create action items of improvement from exercise.## References- [Value Stream Mapping Guide](https://creately.com/blog/diagrams/value-stream-mapping-guide/)- [Value Stream Mapping: How to Visualize Work and Align Leadership for Organizational Transformation](https://books.google.com/books/about/Value_Stream_Mapping_How_to_Visualize_Wo.html?id=MeFrAAAAQBAJ)"
 },
 {
  "title": "WIP",
  "url": "/docs/metrics/work-in-progress.html",
  "content": "# {{ page.title }}Work in Process (WIP) is the total work that has been started but notcompleted. This includes **all** work, defects, tasks, stories, etc.### What is the intended behavior?Teams should limit WIP and work together to complete WIP items in preference tostarting new work.Use WIP limits to identify and exploit constraints in the [Development Cycle Time](./development-cycle-time.html).### How is it improved?- The team should focus on finishing items closest to being ready for  production.- Set and do not exceed WIP limits for the team and for each step.  - WIP limit guidance: 2N-1 where N is the number of team members capable of doing the work.- Keep the Kanban board visible at all times.### How is it gamed?- Teams can update incomplete work to &quot;done&quot; before all quality steps have been  completed.- Reduce the pace of starting new work without focusing on helping to complete  WIP.### When over-driven, what metrics are impacted?- [Quality](./quality.html) metric decreases as additional defects are reported.- [Productivity](./productivity.html) metric decreases."
 },

{
  "title": "Demo",
  "url": "/blog/2019-08-03-demo.html",
  "date": "2019-08-03 00:00:00 +0000",
  "content": "Example blog post introThe rest of the blog post after the first para"
 },
 {
  "title": "",
  "url": "",
  "date": "",
  "content": ""
 }
]